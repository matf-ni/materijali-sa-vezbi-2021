{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraživanje informacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retke matrice se pojavljuju u mnogim domenima. Sistemi preporuka, obrada teksta, kompjuterska vizija ili grafovska modelovanja su samo neki od njih. U nastavku će biti prikazan jedan pojednostavljen sistem za pretraživanje informacija koji za zadati upit korisnika treba da pronađe najrelevantniji dokument kolekcije dokumenata. <img src='assets/ir_system.png' style='height: 300px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za razliku od reprezentacije teksta koju smo koristiti u zadatku sumarizacije, u ovom problemu ćemo za reprezentaciju dokumenata i upita koristiti Tf-Idf vektorizacije. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF reprezentacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prvi korak u obradi kolekcije dokumenata je kreiranje `vokabulara`. Ovaj zadatak podrazumeva izdvajanje svih reči koje se nalaze u kolekciji dokumenata i njihovo leksikografsko sortiranje. U realnim zadacima, u zavisnosti od kolekcije sa kojom se radi, veličina vokabulara može varirati od 10000 do 100000 reči. Da bi se redukovala dimenzija vokabulara, samo izdvajenje reči može da prati filtriranje dopustivih reči, na primer, izbacivanje brojeva, interpunkcije, reči koje se retko pojavljuju poput pravopisnih propusta, reči koje se često pojavljuju poput članova ili predloga. Takođe, izdvajanje reči može pratiti i njihova normalizacija. Na primer, reči *playing*, *played* i *plays* se mogu svesti na istu lingvističku formu (lemu) *play* ili na neki drugi veštački koren (engl. stem), na primer *pla*, koji bi ukazao na zajedničko značenje. \n",
    "\n",
    "Svaki dokument polazne kolekcije je dalje potrebno izraziti vektorski u terminima izdvojenog vokabulara tako što se na pozicijima koje odgovaraju rečima koje sadrže upisuju odgovorajuće težine. Na ostalim pozicijama se upisuju nule pa su dobijene reprezentacije dokumenata vrlo retke. \n",
    "\n",
    "<img src='assets/tfidf_matrix.png'>\n",
    "\n",
    "Težine koje odgovaraju pojedinačnim rečima se mogu računati na razne načine. TF-IDF reprezentacija očekuje da se u obzir uzme frekvencija same reči (engl. term frequency) u dokumentu, kao i njena inverzna frekvencija dokumenta (engl. inverse document frequency) kojom se ukazuje na prisutnost reči u celoj kolekciji dokumenata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Težina *tf-idf* se računa kao proizvod faktora $Tf(t, d)$ i $Idf(t, D)$.\n",
    "\n",
    "$Tf(t, d)$ predstavlja količnik broja pojavljivanja termina (reči) $t$ u dokumentu $d$ i ukupnog broja reči u dokumentu $d$ i računa se kao\n",
    "$$Tf(t, d) = \\frac{count(t)}{|d|}$$\n",
    "\n",
    "$Idf(t, D)$ predstavlja logaritam količnika ukupnog broja dokumenata skupa $D$ i broja dokumenata (iz skupa \n",
    "$D$) u kojima se pojavljuje termin (reč) $t$ i računa se kao\n",
    "$$Idf(t, D) = log(\\frac{|D|}{N_t})$$\n",
    "\n",
    "\n",
    "$$TfIdf(t, d, D) =Tf(t, d)\\cdot Idf(t, D)$$\n",
    "\n",
    "Važnost termina (reči) raste sa rastom broja njegovog pojavljivanja u dokumentu, ali se otežava njegovim ukupnim brojem pojavljivanja u celokupnom skupu dokumenata (rečima koje se pojavljuju u većem broju dokumenata pridružuje se manja vrednost jer je i njihova diskriminativnost manja).\n",
    "\n",
    "Postoje i mnoge varijacije na temu vrednosti ovih faktora o kojima se može više pročitati u članku na [Vikipediji](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) ili u [prezentaciji](https://slideplayer.com/slide/11565250/) koja prati sadržaj knjige *Natural Language and Speech Processing* autora Dana Džurafskog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi ćemo za računanje ovakvih reprezentacija iskoristiti podršku `scikit-learn` biblioteke i njenu klasu `TfIdVectorizer`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolekcija dokumenata sa kojom ćemo raditi je poznata pod imenom `20newsgroup`. Ona sadrži kolekciju 18000 *newsgroup* postova razvrstanih u 20 kategorija. Mi ćemo u radu upotrebiti dve kategorije, `sci.space` i `comp.graphics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.graphics', 'sci.space']\n",
    "documents = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo pogledati kako izgleda jedan dokument kolekcije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: newmme@helios.tn.cornell.edu (Mark E. J. Newman)\n",
      "Subject: HELP: advice on what video system to buy\n",
      "Keywords: video, RS6000\n",
      "Organization: Cornell University\n",
      "Lines: 22\n",
      "\n",
      "If this question is covered elsewhere, I apologize, but I need information\n",
      "fast.\n",
      "\n",
      "My department has been given a large sum of money to install a video system\n",
      "on our network of IBM RS6000 workstations.  This is not an area in which I\n",
      "have any expertise, so I wonder if anyone out there can offer advice.  We\n",
      "would like a system, based either on VHS or 8mm video which will allow one \n",
      "write video, frame by frame on tape for play-back in real time.  It's for\n",
      "visualization of physics problems.  Can anyone tell me what hardware is\n",
      "available which would work for our system?  Some support software is\n",
      "obviously needed too, but nothing particularly sophisticated, since the\n",
      "software we actually use for the visualization is all already written.\n",
      "\n",
      "Please email with replies, as I don't read this group.  Many thanks for your\n",
      "help.\n",
      "\n",
      "Dr. M. E. J. Newman.\n",
      "Department of Physics,\n",
      "Cornell University.\n",
      "newmme@helios.tn.cornell.edu\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(documents.data[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: newmme@helios.tn.cornell.edu (Mark E. J. Newman)\\nSubject: HELP: advice on what video system to buy\\nKeywords: video, RS6000\\nOrganization: Cornell University\\nLines: 22\\n\\nIf this question is covered elsewhere, I apologize, but I need information\\nfast.\\n\\nMy department has been given a large sum of money to install a video system\\non our network of IBM RS6000 workstations.  This is not an area in which I\\nhave any expertise, so I wonder if anyone out there can offer advice.  We\\nwould like a system, based either on VHS or 8mm video which will allow one \\nwrite video, frame by frame on tape for play-back in real time.  It's for\\nvisualization of physics problems.  Can anyone tell me what hardware is\\navailable which would work for our system?  Some support software is\\nobviously needed too, but nothing particularly sophisticated, since the\\nsoftware we actually use for the visualization is all already written.\\n\\nPlease email with replies, as I don't read this group.  Many thanks for your\\nhelp.\\n\\nDr. M. E. J. Newman.\\nDepartment of Physics,\\nCornell University.\\nnewmme@helios.tn.cornell.edu\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolekciju ćemo pripremiti tako što ćemo eliminisati početne *From:*, *Subject:*, *Keywords:\", *Organization:*, *Lines:* i *Distribution:* linije i zameniti pojavljivanja znaka za novi red belinom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_cleaner(document):\n",
    "    clean_document = []\n",
    "    \n",
    "    lines = document.split('\\n')\n",
    "    for line in lines:\n",
    "        if  line.startswith('From:') or \\\n",
    "            line.startswith('Subject:') or \\\n",
    "            line.startswith('Keywords:') or \\\n",
    "            line.startswith('Organization:') or \\\n",
    "            line.startswith('Lines:') or \\\n",
    "            line.startswith('Distribution:'):\n",
    "            continue\n",
    "        else:\n",
    "            clean_line = line.replace('\\n>', ' ')\n",
    "            clean_line = clean_line.replace('\\n', ' ')\n",
    "            clean_document.append(clean_line)\n",
    "            \n",
    "    return \" \".join(clean_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" If this question is covered elsewhere, I apologize, but I need information fast.  My department has been given a large sum of money to install a video system on our network of IBM RS6000 workstations.  This is not an area in which I have any expertise, so I wonder if anyone out there can offer advice.  We would like a system, based either on VHS or 8mm video which will allow one  write video, frame by frame on tape for play-back in real time.  It's for visualization of physics problems.  Can anyone tell me what hardware is available which would work for our system?  Some support software is obviously needed too, but nothing particularly sophisticated, since the software we actually use for the visualization is all already written.  Please email with replies, as I don't read this group.  Many thanks for your help.  Dr. M. E. J. Newman. Department of Physics, Cornell University. newmme@helios.tn.cornell.edu   \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_cleaner(documents.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_documents = [document_cleaner(document) for document in documents.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukupna broj dokumenata u kolekciji je: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1177"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfIdfVectorizer` će za zadatu kolekciju kreirati Tf-Idf matricu. Opciono mu se mogu proslediti parametri podešavanja, na primer, mi ćemo isključiti sve reči koje imaju manje od 5 pojavljivanja (parametar `min_df` sa vrednošću 5), sve reči ćemo svesti na zapis malim slovima (parametar `lowercase` sa podrazumevanom vrednošću True), isključićemo stop reči za engleski jezik (parametar `stop_words` sa vrednošću english), a pod rečima ćemo smatrati niske karaktera opisane regularnim izrazom \\\\b\\\\w\\\\w+\\\\b (podrazumevana vrednost `token_pattern` parametra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(min_df=5, stop_words='english')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(clean_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izdvojene reči vokabulara se mogu pročitati preko svojstva `vocabulary_` koje predstavlja rečnik svi reči i njihovog broja pojavljivanja. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4746"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leksikografski uređen spisak reči se može dobiti metodom `get_feature_names`. Ispod su prikazane reči na pozicijama od 1000 do 1020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clouds',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cm',\n",
       " 'cmu',\n",
       " 'coast',\n",
       " 'code',\n",
       " 'codec',\n",
       " 'coded',\n",
       " 'codes',\n",
       " 'coffee',\n",
       " 'coffman',\n",
       " 'col',\n",
       " 'cold',\n",
       " 'collapse',\n",
       " 'collect',\n",
       " 'collecting',\n",
       " 'collection',\n",
       " 'collections',\n",
       " 'college']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[1000:1020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizom ovih reči se mogu dobiti još neke ideje koje se tiču čišćenja i pripreme teksta. Na primer, možete probati da izbacite brojeve iz vokabulara modifikacijom `token_pattern` regularnog izraza. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mi ćemo korišćenjem ovog vektorizatora dalje transformisati celu kolekciju u Tf-Idf matricu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_documents = vectorizer.transform(clean_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo ispitati strukturu ovako dobijene matrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica koja se generiše je u CSR formatu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorized_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Svaki dokument je opisan vektorom dužine 4746."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177, 4746)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo izračunati i prosečan broj ne-nula vrednosti po dokumentu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.04078164825829"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnz_per_document = vectorized_documents.nnz / vectorized_documents.shape[0]\n",
    "nnz_per_document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sve navedene informacije nam govore da je dobijena matrica izrazito retka, sa oko 1.6% ne-nula vrednosti po dokumentu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recimo da nas interesuju dokumenti koji odgovaraju upitu `computer science`. Upit ćemo pripremiti na isti način kao što smo pripremili i dokumente kako bi dobili iste reprezentacije."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"computer science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_query = vectorizer.transform([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostaje još da pronađemo dokument koji je najrelevantniji za zadati upit. Iskoristićemo kosinusnu sličnost kao meru preklapanja upita `query` i dokumenta `document`. Kosinusna sličnost predstavlja vrednost kosinusa ugla između vektorskih reprezentacija dokumenata `document` i upita `query`. <img src='assets/cosine_similarity.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(document, query):\n",
    "    similarity = np.inner(document, query.reshape(-1,1)) / (sparse.linalg.norm(document) * sparse.linalg.norm(query))\n",
    "    \n",
    "    # rezultat skalarnog prozivoda je retki vektor dizmenzije 1x1 pa je ceo rezultat retki vektor dimenzije 1x1\n",
    "    # zbog toga pozivamo funkciju toarray() i ocitavamo cisto numericku vrednost slicnosti\n",
    "    return similarity.toarray()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalje računamo vrednosti sličnosti za sve dokumente i zadati upit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py:581: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return self.astype(np.float_)._mul_scalar(1./other)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range (0, vectorized_documents.shape[0]):\n",
    "    score = cosine_similarity(vectorized_documents.getrow(i), vectorized_query)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rangiranje dokumenata vršimo po relevantnosti tj. po vrednosti kosinusne sličnosti, od najrelevantnijeg ka najmanje relevantnom dokumentu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(scores)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naš sistem bi vratio sledeći rezultat iz originalne kolekcije:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: greg@cs.uct.ac.za (Gregory Torrance)\\nSubject: Automatic layout of state diagrams\\nOrganization: Computer Science Department, University of Cape Town\\nLines: 18\\n\\nHi,\\n\\nI'm hoping someone out there will be able to help our computer science\\nproject group. We are doing computer science honours, and our project\\nis to do a 'graphical simulator for a finite state automata'.\\n\\nBasically, the program must draw a diagram of a FSA from a textual grammar,\\nshowing circles for states, and labeled arc's in-between.\\n\\nThe problem is working out the best way to layout the states, and draw the\\narc's in-between so that as few arc's as possible cross each other.\\n\\nIf anyone has any suggestions/algorithms/bug-free ready to compile C code :) \\nthat might help us, it would be much appreciated.\\n\\nThanks in advance,\\n\\nGregory\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.data[ranking[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izračunata sličnost ima vrednost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.276958928131604"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[ranking[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redni broj najrelevantnijeg dokumenta u kolekciji je:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativno, za računanje kosinusne sličnosti mogli smo iskoristiti i ugrađenju funkciju `pairwise.cosine_similarity` paketa `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scores = pairwise.cosine_similarity(vectorized_documents, vectorized_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najveća ocena je dobijena za dokument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(new_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrednost ocene je: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.276958928131604"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(new_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
